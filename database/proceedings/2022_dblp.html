<title>Proceedings of the 23rd International Society for Music Information Retrieval Conference, ISMIR 2022, Bengaluru, India, December 4-8, 2022</title>
<booktitle>ISMIR 2022</booktitle>
<editor>[FILL IN MANUALLY]</editor>
<publisher></publisher>
<series></series>
<volume></volume>
<year>2022</year>
<issn></issn>
<isbn>978-1-7327299-2-6</isbn>

<h2>Papers</h2>
<ul>
<li>Yixiao Zhang, Junyan Jiang, Gus Xia, Simon Dixon:
Interpreting Song Lyrics with an Audio-Informed Pre-trained Language Model.
19-26
<ee>https://archives.ismir.net/ismir2022/paper/000001.pdf</ee>
<li>Tsung-Ping Chen, Li Su:
Toward postprocessing-free neural networks for joint beat and downbeat estimation.
27-35
<ee>https://archives.ismir.net/ismir2022/paper/000002.pdf</ee>
<li>Matan Gover, Oded Zewi:
Music Translation: Generating Piano Arrangements in Different Playing Levels.
36-43
<ee>https://archives.ismir.net/ismir2022/paper/000003.pdf</ee>
<li>Ian Simon, Joshua Gardner, Curtis Hawthorne, Ethan Manilow, Jesse Engel:
Scaling Polyphonic Transcription with Mixtures of Monophonic Transcriptions.
44-51
<ee>https://archives.ismir.net/ismir2022/paper/000004.pdf</ee>
<li>Anup Singh, Kris Demuynck, Vipul Arora:
Attention-based audio embeddings for query-by-example.
52-58
<ee>https://archives.ismir.net/ismir2022/paper/000005.pdf</ee>
<li>Otso Björklund:
SIATEC-C: Computationally efficient repeated pattern discovery in polyphonic music.
59-66
<ee>https://archives.ismir.net/ismir2022/paper/000006.pdf</ee>
<li>Marcel A Vélez Vásquez, John Ashley Burgoyne:
Tailed U-Net: Multi-Scale Music Representation Learning.
67-75
<ee>https://archives.ismir.net/ismir2022/paper/000007.pdf</ee>
<li>Da-Yi Wu, Wen-Yi Hsiao, Fu-Rong Yang, Oscar D Friedman, Warren Jackson, Scott Bruzenak, Yi-Wen Liu, Yi-Hsuan Yang:
DDSP-based Singing Vocoders: A New Subtractive-based Synthesizer and A Comprehensive Evaluation.
76-83
<ee>https://archives.ismir.net/ismir2022/paper/000008.pdf</ee>
<li>Elio Quinton:
Equivariant self-supervision for musical tempo estimation.
84-92
<ee>https://archives.ismir.net/ismir2022/paper/000009.pdf</ee>
<li>Yuqiang Li, Shengchen Li, George Fazekas:
How Music features and Musical Data Representations Affect Objective Evaluation of Music Composition: A Review of CSMT Data Challenge 2020.
93-99
<ee>https://archives.ismir.net/ismir2022/paper/000010.pdf</ee>
<li>Eunjin Choi, Yoonjin Chung, Seolhee Lee, Jongik Jeon, Taegyun Kwon, Juhan Nam:
YM2413-MDB: A Multi-Instrumental FM Video Game Music Dataset with Emotion Annotations.
100-108
<ee>https://archives.ismir.net/ismir2022/paper/000011.pdf</ee>
<li>Anil Venkatesh, Viren Sachdev:
Detecting Symmetries of All Cardinalities With Application to Musical 12-Tone Rows.
109-115
<ee>https://archives.ismir.net/ismir2022/paper/000012.pdf</ee>
<li>Jaehun Kim, Cynthia C. S. Liem:
The power of deep without going deep? A study of HDPGMM music representation learning.
116-124
<ee>https://archives.ismir.net/ismir2022/paper/000013.pdf</ee>
<li>Daiki Naruse, Tomoyuki Takahata, Yusuke Mukuta, Tatsuya Harada:
Pop Music Generation with Controllable Phrase Lengths.
125-131
<ee>https://archives.ismir.net/ismir2022/paper/000014.pdf</ee>
<li>Yen-Tung Yeh, Yi-Hsuan Yang, Bo-Yu Chen:
Exploiting Pre-trained Feature Networks for Generative Adversarial Networks in Audio-domain Loop Generation.
132-140
<ee>https://archives.ismir.net/ismir2022/paper/000015.pdf</ee>
<li>Daiyu Zhang, Ju-Chiang Wang, Katerina Kosta, Jordan B. L. Smith, Shicen Zhou:
Modeling the rhythm from lyrics for melody generation of pop songs.
141-148
<ee>https://archives.ismir.net/ismir2022/paper/000016.pdf</ee>
<li>Simeon Rau, Frank Heyen, Stefan Wagner, Michael Sedlmair:
Visualization for AI-Assisted Composing.
151-159
<ee>https://archives.ismir.net/ismir2022/paper/000017.pdf</ee>
<li>Ellie Bean Abrams, Eva Muñoz Vidal, Claire Pelofi, Pablo Ripollés:
Retrieving musical information from neural data: how cognitive features enrich acoustic ones.
160-168
<ee>https://archives.ismir.net/ismir2022/paper/000018.pdf</ee>
<li>Jingwei Zhao, Gus Xia, Ye Wang:
Beat Transformer: Demixed Beat and Downbeat Tracking with Dilated Self-Attention.
169-177
<ee>https://archives.ismir.net/ismir2022/paper/000019.pdf</ee>
<li>Seungyeon Rhyu, Sarah Kim, Kyogu Lee:
Sketching the Expression: Flexible Rendering of Expressive Piano Performance with Self-Supervised Learning.
178-185
<ee>https://archives.ismir.net/ismir2022/paper/000020.pdf</ee>
<li>Karim M. Ibrahim, Elena V. Epure, Geoffroy Peeters, Gaël Richard:
Exploiting Device and Audio Data to Tag Music with User-Aware Listening Contexts.
186-192
<ee>https://archives.ismir.net/ismir2022/paper/000021.pdf</ee>
<li>Yueh-Kao Wu, Ching-Yu Chiu, Yi-Hsuan Yang:
Jukedrummer: Conditional Beat-aware Audio-domain Drum Accompaniment Generation via Transformer VQ-VAE.
193-200
<ee>https://archives.ismir.net/ismir2022/paper/000022.pdf</ee>
<li>Junyan Jiang, Daniel Chin, Yixiao Zhang, Gus Xia:
Learning Hierarchical Metrical Structure Beyond Measures.
201-209
<ee>https://archives.ismir.net/ismir2022/paper/000023.pdf</ee>
<li>Francisco C. F. Almeida, Gilberto Bernardes, Christof Weiss:
Mid-level Harmonic Audio Features for Musical Style Classification.
210-217
<ee>https://archives.ismir.net/ismir2022/paper/000024.pdf</ee>
<li>Johannes Imort, Giorgio Fabbro, Marco A Martinez Ramirez, Stefan Uhlich, Yuichiro Koyama, Yuki Mitsufuji:
Distortion Audio Effects: Learning How to Recover the Clean Signal.
218-225
<ee>https://archives.ismir.net/ismir2022/paper/000025.pdf</ee>
<li>Antonio Ríos-Vila, Jose M. Inesta, Jorge Calvo-Zaragoza:
End-to-End Full-Page Optical Music Recognition for Mensural Notation.
226-232
<ee>https://archives.ismir.net/ismir2022/paper/000026.pdf</ee>
<li>Bruno Di Giorgi, Mark Levy, Richard Sharp:
Mel Spectrogram Inversion with Stable Pitch.
233-239
<ee>https://archives.ismir.net/ismir2022/paper/000027.pdf</ee>
<li>Xingjian Du, Huidong Liang, Yuan Wan, Yuheng Lin, Ke Chen, Bilei Zhu, Zejun Ma:
Latent feature augmentation for chorus detection.
240-247
<ee>https://archives.ismir.net/ismir2022/paper/000028.pdf</ee>
<li>Li Yi, Haochen Hu, Jingwei Zhao, Gus Xia:
AccoMontage2: A Complete Harmonization and Accompaniment Arrangement System.
248-255
<ee>https://archives.ismir.net/ismir2022/paper/000029.pdf</ee>
<li>Matthew C Mccallum, Filip Korzeniowski, Sergio Oramas, Fabien Gouyon, Andreas Ehmann:
Supervised and Unsupervised Learning of Audio Representations for Music Understanding.
256-263
<ee>https://archives.ismir.net/ismir2022/paper/000030.pdf</ee>
<li>Rishabh A Dahale, Vaibhav Vinayak Talwadker, Preeti Rao, Prateek Verma:
Generating Coherent Drum Accompaniment with Fills and Improvisations.
264-271
<ee>https://archives.ismir.net/ismir2022/paper/000031.pdf</ee>
<li>Alia Morsi, Xavier Serra:
Bottlenecks and solutions for audio to score alignment research.
272-279
<ee>https://archives.ismir.net/ismir2022/paper/000032.pdf</ee>
<li>Martin Clayton, Preeti Rao, Nithya Shikarpur, Sujoy Roychowdhury, Jin Li:
Raga Classification From Vocal Performances Using Multimodal Analysis  .
283-290
<ee>https://archives.ismir.net/ismir2022/paper/000033.pdf</ee>
<li>Oleg Lesota, Emilia Parada-Cabaleiro, Stefan Brandl, Elisabeth Lex, Navid Rekabsaz, Markus Schedl:
Traces of Globalization in Online Music Consumption Patterns and Results of Recommendation Algorithms.
291-297
<ee>https://archives.ismir.net/ismir2022/paper/000034.pdf</ee>
<li>Kongmeng Liew, Vipul Mishra, Yangyang Zhou, Elena V. Epure, Romain Hennequin, Shoko Wakamiya, Eiji Aramaki:
Network Analyses for Cross-Cultural Music Popularity.
298-305
<ee>https://archives.ismir.net/ismir2022/paper/000035.pdf</ee>
<li>Polykarpos Polykarpidis, Dionysios Kalofonos, Dimitrios Balageorgos, Christina Anagnostopoulou:
Three related corpora in Middle Byzantine music notation and a preliminary comparative analysis.
306-313
<ee>https://archives.ismir.net/ismir2022/paper/000036.pdf</ee>
<li>Dichucheng Li, Yulun Wu, Qinyu Li, Jiahao Zhao, Yi Yu, Fan Xia, Wei Li:
Playing Technique Detection by Fusing Note Onset Information in Guzheng Performance.
314-320
<ee>https://archives.ismir.net/ismir2022/paper/000037.pdf</ee>
<li>Babak Nikzat, Rafael Caro Repetto:
KDC: an open corpus for computational research of dastgāhi music.
321-328
<ee>https://archives.ismir.net/ismir2022/paper/000038.pdf</ee>
<li>Ke Nie:
Inaccurate Prediction or Genre Evolution? Rethinking Genre Classification.
329-336
<ee>https://archives.ismir.net/ismir2022/paper/000039.pdf</ee>
<li>Thomas Nuttall, Genís Plaja-Roglans, Lara Pearson, Xavier Serra:
In Search of Sañcāras: Tradition-informed Repeated Melodic Pattern Recognition in Carnatic Music.
337-344
<ee>https://archives.ismir.net/ismir2022/paper/000040.pdf</ee>
<li>Zhaowen Wang, Mingjin Che, Yue Yang, Wen Wu Meng, Qinyu Li, Fan Xia, Wei Li:
Automatic Chinese National Pentatonic Modes Recognition Using Convolutional Neural Network.
345-352
<ee>https://archives.ismir.net/ismir2022/paper/000041.pdf</ee>
<li>David Gillman, Atalay Kutlay, Uday Goyat:
Teach Yourself Georgian Folk Songs Dataset: A Annotated Corpus Of Traditional Vocal Polyphony.
353-360
<ee>https://archives.ismir.net/ismir2022/paper/000042.pdf</ee>
<li>Lucas S Maia, Martín Rocamora, Luiz W P Biscainho, Magdalena Fuentes:
Adapting meter tracking models to Latin American music.
361-368
<ee>https://archives.ismir.net/ismir2022/paper/000043.pdf</ee>
<li>Kaustuv Kanti Ganguli, Sertan Şentürk, Carlos Guedes:
Critiquing Task- versus Goal-oriented Approaches: A Case for Makam Recognition.
369-376
<ee>https://archives.ismir.net/ismir2022/paper/000044.pdf</ee>
<li>Charilaos Papaioannou, Ioannis Valiantzas, Theodore Giannakopoulos, Maximos Kaliakatsos-Papakostas, Alexandros Potamianos:
A Dataset for Greek Traditional and Folk Music: Lyra.
377-383
<ee>https://archives.ismir.net/ismir2022/paper/000045.pdf</ee>
<li>Yuya Yamamoto, Juhan Nam, Hiroko Terasawa:
Analysis and detection of singing techniques in repertoires of J-POP solo singers.
384-391
<ee>https://archives.ismir.net/ismir2022/paper/000046.pdf</ee>
<li>Lele Liu, Qiuqiang Kong, Veronica Morfi, Emmanouil Benetos:
Performance MIDI-to-score conversion by neural beat tracking.
395-402
<ee>https://archives.ismir.net/ismir2022/paper/000047.pdf</ee>
<li>Sangjun Han, Hyeongrae Ihm, Moontae Lee, Woohyung Lim:
Symbolic Music Loop Generation with Neural Discrete Representations.
403-410
<ee>https://archives.ismir.net/ismir2022/paper/000048.pdf</ee>
<li>Marco A Martinez Ramirez, Weihsiang Liao, Chihiro Nagashima, Giorgio Fabbro, Stefan Uhlich, Yuki Mitsufuji:
Automatic music mixing with deep learning and out-of-domain data.
411-418
<ee>https://archives.ismir.net/ismir2022/paper/000049.pdf</ee>
<li>Mahshid Alinoori, Vassilios Tzerpos:
Music-STAR: a Style Translation system for Audio-based Re-instrumentation.
419-426
<ee>https://archives.ismir.net/ismir2022/paper/000050.pdf</ee>
<li>Darius Afchar, Romain Hennequin, Vincent Guigue:
Learning Unsupervised Hierarchies of Audio Concepts.
427-436
<ee>https://archives.ismir.net/ismir2022/paper/000051.pdf</ee>
<li>Massimo Quadrana, Antoine Larreche-Mouly, Matthias Mauch:
Multi-objective Hyper-parameter Optimization of Behavioral Song Embeddings.
437-445
<ee>https://archives.ismir.net/ismir2022/paper/000052.pdf</ee>
<li>Huan Zhang, Jingjing Tang, Syed Rm Rafee, Simon Dixon, George Fazekas, Geraint A. Wiggins:
ATEPP: A Dataset of Automatically Transcribed Expressive Piano Performance.
446-453
<ee>https://archives.ismir.net/ismir2022/paper/000053.pdf</ee>
<li>Chen Zhang, Jiaxing Yu, Luchin Chang, Xu Tan, Jiawei Chen, Tao Qin, Kejun Zhang:
PDAugment: Data Augmentation by Pitch and Duration Adjustments for Automatic Lyrics Transcription.
454-461
<ee>https://archives.ismir.net/ismir2022/paper/000054.pdf</ee>
<li>Chitralekha Gupta, Yize Wei, Zequn Gong, Purnima Kamath, Zhuoyao Li, Lonce Wyse:
Parameter Sensitivity of Deep-Feature based Evaluation Metrics for Audio Textures.
462-468
<ee>https://archives.ismir.net/ismir2022/paper/000055.pdf</ee>
<li>Igor Vatolkin, Cory Mckay:
Stability of Symbolic Feature Group Importance in the Context of Multi-Modal Music Classification.
469-476
<ee>https://archives.ismir.net/ismir2022/paper/000056.pdf</ee>
<li>Franca Bittner, Marcel Gonzalez, Maike L Richter, Hanna Lukashevich, Jakob Abeßer:
Multi-pitch Estimation meets Microphone Mismatch: Applicability of Domain Adaptation.
477-484
<ee>https://archives.ismir.net/ismir2022/paper/000057.pdf</ee>
<li>Chris Donahue, John Thickstun, Percy Liang:
Melody transcription via generative pre-training.
485-492
<ee>https://archives.ismir.net/ismir2022/paper/000058.pdf</ee>
<li>Yigitcan Özer, Meinard Müller:
Source Separation of Piano Concertos with Test-Time Adaptation.
493-500
<ee>https://archives.ismir.net/ismir2022/paper/000059.pdf</ee>
<li>Martha E Thomae Elias, Julie Cumming, Ichiro Fujinaga:
Counterpoint Error-Detection Tools for Optical Music Recognition of Renaissance Polyphonic Music.
501-508
<ee>https://archives.ismir.net/ismir2022/paper/000060.pdf</ee>
<li>Louis Couturier, Louis Bigo, Florence Leve:
A Dataset of Symbolic Texture Annotations in Mozart Piano Sonatas.
509-516
<ee>https://archives.ismir.net/ismir2022/paper/000061.pdf</ee>
<li>Nazif Can Tamer, Pedro Ramoneda, Xavier Serra:
Violin Etudes: A Comprehensive Dataset for f0 Estimation and Performance Analysis.
517-524
<ee>https://archives.ismir.net/ismir2022/paper/000062.pdf</ee>
<li>Nikita Srivatsan, Taylor Berg-Kirkpatrick:
Checklist Models for Improved Output Fluency in Piano Fingering Prediction.
525-531
<ee>https://archives.ismir.net/ismir2022/paper/000063.pdf</ee>
<li>Jaidev Shriram, Makarand Tapaswi, Vinoo Alluri:
Sonus Texere! Automated Dense Soundtrack Construction for Books using Movie Adaptations.
535-542
<ee>https://archives.ismir.net/ismir2022/paper/000064.pdf</ee>
<li>Marco Pasini, Jan Schlüter:
Musika! Fast Infinite Waveform Music Generation.
543-550
<ee>https://archives.ismir.net/ismir2022/paper/000065.pdf</ee>
<li>Jiafeng Liu, Yuanliang Dong, Zehua Cheng, Xinran Zhang, Xiaobing Li, Feng Yu, Maosong Sun:
Symphony Generation with Permutation Invariant Language Model.
551-558
<ee>https://archives.ismir.net/ismir2022/paper/000066.pdf</ee>
<li>Qingqing Huang, Aren Jansen, Joonseok Lee, Ravi Ganti, Judith Yue Li, Daniel P W Ellis:
MuLan: A Joint Embedding of Music Audio and Natural Language.
559-566
<ee>https://archives.ismir.net/ismir2022/paper/000067.pdf</ee>
<li>Peiling Lu, Xu Tan, Botao Yu, Tao Qin, Sheng Zhao, Tie-Yan Liu:
MeloForm: Generating Melody with Musical Form based on Expert Systems and Neural Networks.
567-574
<ee>https://archives.ismir.net/ismir2022/paper/000068.pdf</ee>
<li>Chang-Bin Jeon, Kyogu Lee:
Towards robust music source separation on loud commercial music.
575-582
<ee>https://archives.ismir.net/ismir2022/paper/000069.pdf</ee>
<li>Michael Zhou, Andrew Mcgraw, Douglas R Turnbull:
Towards Quantifying the Strength of Music Scenes Using Live Event Data.
583-590
<ee>https://archives.ismir.net/ismir2022/paper/000070.pdf</ee>
<li>Morgan Buisson, Brian Mcfee, Slim Essid, Hélène C.  Crayencour Crayencour:
Learning Multi-Level Representations for Hierarchical Music Structure Analysis..
591-597
<ee>https://archives.ismir.net/ismir2022/paper/000071.pdf</ee>
<li>Curtis Hawthorne, Ian Simon, Adam Roberts, Neil Zeghidour, Joshua Gardner, Ethan Manilow, Jesse Engel:
Multi-instrument Music Synthesis with Spectrogram Diffusion.
598-607
<ee>https://archives.ismir.net/ismir2022/paper/000072.pdf</ee>
<li>Franco Caspe, Andrew Mcpherson, Mark Sandler:
DDX7: Differentiable FM Synthesis of Musical Instrument Sounds.
608-616
<ee>https://archives.ismir.net/ismir2022/paper/000073.pdf</ee>
<li>Mojtaba Heydari, Zhiyao Duan:
Singing beat tracking with Self-supervised front-end and linear transformers.
617-624
<ee>https://archives.ismir.net/ismir2022/paper/000074.pdf</ee>
<li>Saurjya Sarkar, Emmanouil Benetos, Mark Sandler:
EnsembleSet: a new high quality synthesised dataset for chamber ensemble separation.
625-632
<ee>https://archives.ismir.net/ismir2022/paper/000075.pdf</ee>
<li>Tengyu Deng, Eita Nakamura, Kazuyoshi Yoshii:
End-to-End Lyrics Transcription Informed by Pitch and Onset Estimation.
633-639
<ee>https://archives.ismir.net/ismir2022/paper/000076.pdf</ee>
<li>Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas:
Contrastive Audio-Language Learning for Music.
640-649
<ee>https://archives.ismir.net/ismir2022/paper/000077.pdf</ee>
<li>Dmitry Bogdanov, Xavier Lizarraga-Seijas, Pablo Alonso-Jiménez, Xavier Serra:
MusAV: A dataset of relative arousal-valence annotations for validation of audio models.
650-658
<ee>https://archives.ismir.net/ismir2022/paper/000078.pdf</ee>
<li>Shuqi Dai, Huiran Yu, Roger B Dannenberg:
What is missing in deep music generation? A study of repetition and structure in popular music.
659-666
<ee>https://archives.ismir.net/ismir2022/paper/000079.pdf</ee>
<li>Angelo Cesar Mendes Da Silva, Diego F Silva, Ricardo Marcondes Marcacini:
Heterogeneous Graph Neural Network for Music Emotion Recognition.
667-674
<ee>https://archives.ismir.net/ismir2022/paper/000080.pdf</ee>
<li>Mathilde Abrassart, Guillaume Doras:
And what if two musical versions don't share melody, harmony, rhythm, or lyrics ?.
677-684
<ee>https://archives.ismir.net/ismir2022/paper/000081.pdf</ee>
<li>Genís Plaja-Roglans, Marius Miron, Xavier Serra:
A diffusion-inspired training strategy for singing voice extraction in the waveform domain.
685-693
<ee>https://archives.ismir.net/ismir2022/paper/000082.pdf</ee>
<li>Romain Loiseau, Baptiste Bouvier, Yann Teytaut, Elliot Vincent, Mathieu Aubry, Loic Landrieu:
A Model You Can Hear: Audio Identification with Playable Prototypes.
694-700
<ee>https://archives.ismir.net/ismir2022/paper/000083.pdf</ee>
<li>Marcos Acosta, Irmak Bukey, T J Tsai:
An Exploration of Generating Sheet Music Images.
701-708
<ee>https://archives.ismir.net/ismir2022/paper/000084.pdf</ee>
<li>Weixing Wei, Peilin Li, Yi Yu, Wei Li:
HPPNet: Modeling the Harmonic Structure and Pitch Invariance in Piano Transcription.
709-716
<ee>https://archives.ismir.net/ismir2022/paper/000085.pdf</ee>
<li>Pedro L T Neves, José Fornari, João B Florindo:
Generating music with sentiment using Transformer-GANs.
717-725
<ee>https://archives.ismir.net/ismir2022/paper/000086.pdf</ee>
<li>Ke Chen, Hao-Wen Dong, Yi Luo, Julian Mcauley, Taylor Berg-Kirkpatrick, Miller Puckette, Shlomo Dubnov:
Improving Choral Music Separation through Expressive Synthesized Data from Sampled Instruments.
726-732
<ee>https://archives.ismir.net/ismir2022/paper/000087.pdf</ee>
<li>Kyungyun Lee, Gladys Hitt, Emily Terada, Jin Ha Lee:
Ethics of Singing Voice Synthesis: Perceptions of Users and Developers.
733-740
<ee>https://archives.ismir.net/ismir2022/paper/000088.pdf</ee>
<li>Takuya Takahashi, Mathieu Barthet:
Emotion-driven Harmonisation And Tempo Arrangement of Melodies Using Transfer Learning.
741-748
<ee>https://archives.ismir.net/ismir2022/paper/000089.pdf</ee>
<li>Yigitcan Özer, Matej Ištvánek, Vlora Arifi-Müller, Meinard Müller:
Using Activation Functions for Improving Measure-Level Audio Synchronization.
749-755
<ee>https://archives.ismir.net/ismir2022/paper/000090.pdf</ee>
<li>Katerina Kosta, Wei Tsung Lu, Gabriele Medeot, Pierre Chanquion:
A deep learning method for melody extraction from a polyphonic symbolic music representation.
756-763
<ee>https://archives.ismir.net/ismir2022/paper/000091.pdf</ee>
<li>Peter Knees, Bruce Ferwerda, Andreas Rauber, Sebastian Strumbelj, Annabel Resch, Laurenz Tomandl, Valentin Bauer, Fung Yee Tang, Josip Bobinac, Amila Ceranic, Riad Dizdar:
A Reproducibility Study on User-centric MIR Research and Why it is Important.
764-771
<ee>https://archives.ismir.net/ismir2022/paper/000092.pdf</ee>
<li>Noah Schaffer, Boaz Cogan, Ethan Manilow, Max Morrison, Prem Seetharaman, Bryan Pardo:
Music Separation Enhancement with Generative Modeling.
772-780
<ee>https://archives.ismir.net/ismir2022/paper/000093.pdf</ee>
<li>Stefan Lattner:
SampleMatch: Drum Sample Retrieval by Musical Context.
781-788
<ee>https://archives.ismir.net/ismir2022/paper/000094.pdf</ee>
<li>Timothy De Reuse, Ichiro Fujinaga:
A Transformer-Based "Spellchecker" for Detecting Errors in OMR Output.
789-796
<ee>https://archives.ismir.net/ismir2022/paper/000095.pdf</ee>
<li>Vjosa Preniqi, Kyriaki Kalimeri, Charalampos Saitis:
"More than words": Linking Music Preferences and Moral Values through Lyrics.
797-805
<ee>https://archives.ismir.net/ismir2022/paper/000096.pdf</ee>
<li>Jui-Te Wu, Jun-You Wang, Jyh-Shing Roger Jang, Li Su:
A unified model for zero-shot singing voice conversion and synthesis.
809-816
<ee>https://archives.ismir.net/ismir2022/paper/000097.pdf</ee>
<li>Stewart Greenhill, Majid Abdolshah, Vuong Le, Sunil Gupta, Svetha Venkatesh:
Semantic Control of Generative Musical Attributes.
817-824
<ee>https://archives.ismir.net/ismir2022/paper/000098.pdf</ee>
<li>Pablo Alonso-Jiménez, Xavier Serra, Dmitry Bogdanov:
Music Representation Learning Based on Editorial Metadata from Discogs.
825-833
<ee>https://archives.ismir.net/ismir2022/paper/000099.pdf</ee>
<li>Chih-Pin Tan, Alvin W Y Su, Yi-Hsuan Yang:
Melody Infilling with User-Provided Structural Context.
834-841
<ee>https://archives.ismir.net/ismir2022/paper/000100.pdf</ee>
<li>Xichu Ma, Xiao Liu, Bowen Zhang, Ye Wang:
Robust Melody Track Identification in Symbolic Music.
842-849
<ee>https://archives.ismir.net/ismir2022/paper/000101.pdf</ee>
<li>Florian Thalmann, Eita Nakamura, Kazuyoshi Yoshii:
Tracking the Evolution of a Band's Live Performances over Decades.
850-857
<ee>https://archives.ismir.net/ismir2022/paper/000102.pdf</ee>
<li>Ashvala Vinay, Alexander Lerch:
Evaluating Generative Audio Systems and Their Metrics.
858-865
<ee>https://archives.ismir.net/ismir2022/paper/000103.pdf</ee>
<li>Alison B Ma, Alexander Lerch:
Representation Learning for the Automatic Indexing of Sound Effects Libraries.
866-875
<ee>https://archives.ismir.net/ismir2022/paper/000104.pdf</ee>
<li>Francesco Foscarin, Katharina Hoedt, Verena Praher, Arthur Flexer, Gerhard Widmer:
Concept-Based Techniques for "Musicologist-Friendly" Explanations in Deep Music Classifiers.
876-883
<ee>https://archives.ismir.net/ismir2022/paper/000105.pdf</ee>
<li>Maximilian Mayerl, Stefan Brandl, Günther Specht, Markus Schedl, Eva Zangerle:
Verse versus Chorus: Structure-aware Feature Extraction for Lyrics-based Genre Recognition.
884-890
<ee>https://archives.ismir.net/ismir2022/paper/000106.pdf</ee>
<li>Longshen Ou, Xiangming Gu, Ye Wang:
Transfer Learning of wav2vec 2.0 for Automatic Lyric Transcription.
891-899
<ee>https://archives.ismir.net/ismir2022/paper/000107.pdf</ee>
<li>Daniel Szelogowski, Lopamudra Mukherjee, Benjamin Whitcomb:
A Novel Dataset and Deep Learning Benchmark for Classical Music Form Recognition and Analysis.
900-907
<ee>https://archives.ismir.net/ismir2022/paper/000108.pdf</ee>
<li>Guillem Cortès, Alex Ciurana, Emilio Molina, Marius Miron, Owen Meyers, Joren Six, Xavier Serra:
BAF: An audio fingerprinting dataset for broadcast monitoring.
908-916
<ee>https://archives.ismir.net/ismir2022/paper/000109.pdf</ee>
<li>Emmanouil Karystinaios, Gerhard Widmer:
Cadence Detection in Symbolic Classical Music using Graph Neural Networks..
917-924
<ee>https://archives.ismir.net/ismir2022/paper/000110.pdf</ee>
<li>Jingwei Zhao, Gus Xia, Ye Wang:
Domain Adversarial Training on Conditional Variational Auto-Encoder for Controllable Music Generation.
925-932
<ee>https://archives.ismir.net/ismir2022/paper/000111.pdf</ee>
<li>Yang Qu, Yutian Qin, Lecheng Chao, Hangkai Qian, Ziyu Wang, Gus Xia:
Modeling perceptual loudness of piano tone: theory and applications.
933-940
<ee>https://archives.ismir.net/ismir2022/paper/000112.pdf</ee>
<li>Maximilian Damböck, Richard Vogl, Peter Knees:
On the Impact and Interplay of Input Representations and Network Architectures for Automatic Music Tagging.
941-948
<ee>https://archives.ismir.net/ismir2022/paper/000113.pdf</ee>
</ul>
<footer>
