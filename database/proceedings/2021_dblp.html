<title>Proceedings of the 22nd International Society for Music Information Retrieval Conference, ISMIR 2021, Online, 7-12 Nov, 2021</title>
<booktitle>ISMIR 2021</booktitle>
<editor>Jin Ha Lee</editor>
<editor>Alexander Lerch</editor>
<editor>Zhiyao Duan</editor>
<editor>Juhan Nam</editor>
<editor>Preeti Rao</editor>
<editor>Peter Van Kranenburg</editor>
<editor>Ajay Srinivasamurthy</editor>
<publisher></publisher>
<series></series>
<volume></volume>
<year>2021</year>
<issn></issn>
<isbn>978-1-7327299-0-2</isbn>

<h2>Papers</h2>
<ul>
<li>Rohit M A, Amitrajit Bhattacharjee, Preeti Rao:
Four-way Classification of Tabla Strokes with Models Adapted from Automatic Drum Transcription.
19-26
<ee>https://archives.ismir.net/ismir2021/paper/000001.pdf</ee>
<li>Taketo Akama:
A Contextual Latent Space Model: Subsequence Modulation in Melodic Sequence.
27-34
<ee>https://archives.ismir.net/ismir2021/paper/000002.pdf</ee>
<li>María Alfaro-Contreras, David Rizo, Jose M. Inesta, Jorge Calvo-Zaragoza:
OMR-assisted transcription: a case study with early prints.
35-41
<ee>https://archives.ismir.net/ismir2021/paper/000003.pdf</ee>
<li>Stefan A Baumann:
Deeper Convolutional Neural Networks and Broad Augmentation Policies Improve Performance in Musical Key Estimation.
42-49
<ee>https://archives.ismir.net/ismir2021/paper/000004.pdf</ee>
<li>Axel Berndt:
The Music Performance Markup Format and Ecosystem.
50-57
<ee>https://archives.ismir.net/ismir2021/paper/000005.pdf</ee>
<li>Louis Bigo, David Regnier, Nicolas Martin:
Identification of rhythm guitar sections in symbolic tablatures.
58-65
<ee>https://archives.ismir.net/ismir2021/paper/000006.pdf</ee>
<li>Charles Brazier, Gerhard Widmer:
On-Line Audio-to-Lyrics Alignment Based on a Reference Performance.
66-73
<ee>https://archives.ismir.net/ismir2021/paper/000007.pdf</ee>
<li>Aaron Carter-Enyi, Gilad Rabinovitch, Nathaniel Condit-Schultz:
Visualizing Intertextual Form with Arc Diagrams: Contour and Schema-based Methods.
74-80
<ee>https://archives.ismir.net/ismir2021/paper/000008.pdf</ee>
<li>Francisco J. Castellanos, Antonio-Javier Gallego, Jorge Calvo-Zaragoza:
Unsupervised Domain Adaptation for Document Analysis of Music Score Images.
81-87
<ee>https://archives.ismir.net/ismir2021/paper/000009.pdf</ee>
<li>Rodrigo Castellon, Chris Donahue, Percy Liang:
Codified audio language modeling learns useful representations for music information retrieval.
88-96
<ee>https://archives.ismir.net/ismir2021/paper/000010.pdf</ee>
<li>Chin-Jui Chang, Chun-Yi Lee, Yi-Hsuan Yang:
Variable-Length Music Score Infilling via XLNet and Musically Specialized Positional Encoding.
97-104
<ee>https://archives.ismir.net/ismir2021/paper/000011.pdf</ee>
<li>Yi-Wei Chen, Hung-Shin Lee, Yen-Hsing Chen, Hsin-Min Wang:
SurpriseNet: Melody Harmonization Conditioning on User-controlled Surprise Contours.
105-112
<ee>https://archives.ismir.net/ismir2021/paper/000012.pdf</ee>
<li>Vincent K.M. Cheung, Hsuan-Kai Kao, Li Su:
Semi-supervised violin fingering generation using variational autoencoders.
113-120
<ee>https://archives.ismir.net/ismir2021/paper/000013.pdf</ee>
<li>Keunwoo Choi, Yuxuan Wang:
Listen, Read, and Identify: Multimodal Singing Language Identification of Music.
121-127
<ee>https://archives.ismir.net/ismir2021/paper/000014.pdf</ee>
<li>Shreyan Chowdhury, Gerhard Widmer:
On Perceived Emotion in Expressive Piano Performance: Further Experimental Evidence for the Relevance of Mid-level Perceptual Features.
128-134
<ee>https://archives.ismir.net/ismir2021/paper/000015.pdf</ee>
<li>Bas Cornelissen, Willem Zuidema, John Ashley Burgoyne:
Cosine Contours: a Multipurpose Representation for Melodies.
135-142
<ee>https://archives.ismir.net/ismir2021/paper/000016.pdf</ee>
<li>Shuqi Dai, Zeyu Jin, Celso Gomes, Roger Dannenberg:
Controllable deep melody generation via hierarchical music structure representation.
143-150
<ee>https://archives.ismir.net/ismir2021/paper/000017.pdf</ee>
<li>Emir Demirel, Sven Ahlbäck, Simon Dixon:
MSTRE-Net: Multistreaming Acoustic Modeling for Automatic Lyrics Transcription.
151-158
<ee>https://archives.ismir.net/ismir2021/paper/000018.pdf</ee>
<li>Hao-Wen Dong, Chris Donahue, Taylor Berg-Kirkpatrick, Julian Mcauley:
Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music.
159-166
<ee>https://archives.ismir.net/ismir2021/paper/000019.pdf</ee>
<li>Sachinda Edirisooriya, Hao-Wen Dong, Julian Mcauley, Taylor Berg-Kirkpatrick:
An Empirical Evaluation of End-to-End Polyphonic Optical Music Recognition.
167-173
<ee>https://archives.ismir.net/ismir2021/paper/000020.pdf</ee>
<li>Anders Elowsson, Olivier Lartillot:
A Hardanger Fiddle Dataset with Performances Spanning Emotional Expressions and Annotations Aligned using Image Registration.
174-181
<ee>https://archives.ismir.net/ismir2021/paper/000021.pdf</ee>
<li>Jeffrey Ens, Philippe Pasquier:
Building the MetaMIDI Dataset: Linking Symbolic and Audio Musical Data.
182-188
<ee>https://archives.ismir.net/ismir2021/paper/000022.pdf</ee>
<li>Christoph Finkensiep, Martin A Rohrmeier:
Modeling and Inferring Proto-Voice Structure in Free Polyphony.
189-196
<ee>https://archives.ismir.net/ismir2021/paper/000023.pdf</ee>
<li>Francesco Foscarin, Nicolas Audebert, Raphael Fournier-S'Niehotta:
PKSpell: Data-Driven Pitch Spelling and Key Signature Estimation.
197-204
<ee>https://archives.ismir.net/ismir2021/paper/000024.pdf</ee>
<li>Dave Foster, Simon Dixon:
Filosax: A Dataset of Annotated Jazz Saxophone Recordings.
205-212
<ee>https://archives.ismir.net/ismir2021/paper/000025.pdf</ee>
<li>Giovanni Gabbolini, Derek Bridge:
An interpretable music similarity measure based on path interestingness.
213-219
<ee>https://archives.ismir.net/ismir2021/paper/000026.pdf</ee>
<li>Hugo F Flores Garcia, Aldo Aguilar, Ethan Manilow, Bryan Pardo:
Leveraging Hierarchical Structures for Few-Shot Musical Instrument Recognition.
220-228
<ee>https://archives.ismir.net/ismir2021/paper/000027.pdf</ee>
<li>Mark R H Gotham, Rainer Kleinertz, Christof Weiss, Meinard Müller, Stephanie Klauk:
What if the 'When' Implies the 'What'?: Human harmonic analysis datasets clarify the relative role of the separate steps in automatic tonal analysis.
229-236
<ee>https://archives.ismir.net/ismir2021/paper/000028.pdf</ee>
<li>Juan S. Gómez-Cañón, Estefania Cano, Yi-Hsuan Yang, Perfecto Herrera, Emilia Gomez:
Let's agree to disagree: Consensus Entropy Active Learning for Personalized Music Emotion Recognition.
237-245
<ee>https://archives.ismir.net/ismir2021/paper/000029.pdf</ee>
<li>Curtis Hawthorne, Ian Simon, Rigel Swavely, Ethan Manilow, Jesse Engel:
Sequence-to-Sequence Piano Transcription with Transformers.
246-253
<ee>https://archives.ismir.net/ismir2021/paper/000030.pdf</ee>
<li>Ben Hayes, Charalampos Saitis, Gyorgy Fazekas:
Neural Waveshaping Synthesis.
254-261
<ee>https://archives.ismir.net/ismir2021/paper/000031.pdf</ee>
<li>Johannes Hentschel, Fabian C. Moss, Markus Neuwirth, Martin A Rohrmeier:
A semi-automated workflow paradigm for the distributed creation and curation of expert annotations.
262-269
<ee>https://archives.ismir.net/ismir2021/paper/000032.pdf</ee>
<li>Mojtaba Heydari, Frank Cwitkowitz, Zhiyao Duan:
BeatNet: CRNN and Particle Filtering for Online Joint Beat, Downbeat and Meter Tracking.
270-277
<ee>https://archives.ismir.net/ismir2021/paper/000033.pdf</ee>
<li>Yuki Hiramatsu, Eita Nakamura, Kazuyoshi Yoshii:
Joint Estimation of Note Values and Voices for Audio-to-Score Piano Transcription.
278-284
<ee>https://archives.ismir.net/ismir2021/paper/000034.pdf</ee>
<li>Yo-Wei Hsiao, Li Su:
Learning note-to-note affinity for voice segregation and melody line identification of symbolic music data.
285-292
<ee>https://archives.ismir.net/ismir2021/paper/000035.pdf</ee>
<li>Jui-Yang Hsu, Li Su:
VOCANO: A note transcription framework for singing voice in polyphonic music.
293-300
<ee>https://archives.ismir.net/ismir2021/paper/000036.pdf</ee>
<li>Rujing Huang, Bob L. T. Sturm, Andre Holzapfel:
De-centering the West: East Asian Philosophies and the Ethics of Applying Artificial Intelligence to Music.
301-309
<ee>https://archives.ismir.net/ismir2021/paper/000037.pdf</ee>
<li>Tun Min Hung, Bo-Yu Chen, Yen Tung Yeh, Yi-Hsuan Yang:
A Benchmarking Initiative for Audio-domain Music Generation using the FreeSound Loop Dataset.
310-317
<ee>https://archives.ismir.net/ismir2021/paper/000038.pdf</ee>
<li>Hsiao-Tzu Hung, Joann Ching, Seungheon Doh, Nabin Kim, Juhan Nam, Yi-Hsuan Yang:
EMOPIA: A Multi-Modal Pop Piano Dataset For Emotion Recognition and Emotion-based Music Generation.
318-325
<ee>https://archives.ismir.net/ismir2021/paper/000039.pdf</ee>
<li>Kevin Ji, Daniel Yang, Timothy Tsai:
Piano Sheet Music Identification Using Marketplace Fingerprinting.
326-333
<ee>https://archives.ismir.net/ismir2021/paper/000040.pdf</ee>
<li>Keunhyoung Kim, Jongpil Lee, Sangeun Kum, Juhan Nam:
Learning a cross-domain embedding space of vocal and mixed audio with a structure-preserving triplet loss.
334-341
<ee>https://archives.ismir.net/ismir2021/paper/000041.pdf</ee>
<li>Qiuqiang Kong, Yin Cao, Haohe Liu, Keunwoo Choi, Yuxuan Wang:
Decoupling Magnitude and Phase Estimation with Deep ResUNet for Music Source Separation.
342-349
<ee>https://archives.ismir.net/ismir2021/paper/000042.pdf</ee>
<li>Filip Korzeniowski, Sergio Oramas, Fabien Gouyon:
Artist Similarity Using Graph Neural Networks.
350-357
<ee>https://archives.ismir.net/ismir2021/paper/000043.pdf</ee>
<li>Jin Ha Lee, Arpita Bhattacharya, Ria Antony, Nicole Santero, Anh Le:
“Finding Home”: Understanding How Music Supports Listeners’ Mental Health through a Case Study of BTS.
358-365
<ee>https://archives.ismir.net/ismir2021/paper/000044.pdf</ee>
<li>Harin Lee, Frank Höger, Marc Schönwiesner, Minsu Park, Nori Jacoby:
Cross-cultural Mood Perception in Pop Songs and its Alignment with Mood Detection Algorithms.
366-373
<ee>https://archives.ismir.net/ismir2021/paper/000045.pdf</ee>
<li>Jordan Lenchitz:
Reconsidering quantization in MIR.
374-380
<ee>https://archives.ismir.net/ismir2021/paper/000046.pdf</ee>
<li>Liwei Lin, Gus Xia, Qiuqiang Kong, Junyan Jiang:
A unified model for zero-shot music source separation, transcription and synthesis.
381-388
<ee>https://archives.ismir.net/ismir2021/paper/000047.pdf</ee>
<li>Carlos Lordelo, Emmanouil Benetos, Simon Dixon, Sven Ahlbäck:
Pitch-Informed Instrument Assignment using a Deep Convolutional Network with Multiple Kernel Shapes.
389-395
<ee>https://archives.ismir.net/ismir2021/paper/000048.pdf</ee>
<li>Wei-Tsung Lu, Ju-Chiang Wang, Minz Won, Keunwoo Choi, Xuchen Song:
SpecTNT: a Time-Frequency Transformer for Music Audio.
396-403
<ee>https://archives.ismir.net/ismir2021/paper/000049.pdf</ee>
<li>Néstor Nápoles López, Mark R H Gotham, Ichiro Fujinaga:
AugmentedNet: A Roman Numeral Analysis Network with Synthetic Training Examples and Additional Tonal Tasks.
404-411
<ee>https://archives.ismir.net/ismir2021/paper/000050.pdf</ee>
<li>Vincenzo Madaghiele, Pasquale Lisena, Raphael Troncy:
MINGUS: Melodic Improvisation Neural Generator Using Seq2Seq.
412-419
<ee>https://archives.ismir.net/ismir2021/paper/000051.pdf</ee>
<li>Ninon Lizé Masclef, Andrea Vaglio, Manuel Moussallam:
User-centered evaluation of lyrics-to-audio alignment.
420-427
<ee>https://archives.ismir.net/ismir2021/paper/000052.pdf</ee>
<li>Naotake Masuda, Daisuke Saito:
Synthesizer Sound Matching with Differentiable DSP.
428-434
<ee>https://archives.ismir.net/ismir2021/paper/000053.pdf</ee>
<li>Andrew Mcleod, Martin A Rohrmeier:
A Modular System for the Harmonic Analysis of Musical Scores using a Large Vocabulary.
435-442
<ee>https://archives.ismir.net/ismir2021/paper/000054.pdf</ee>
<li>Gianluca Micchi, Katerina Kosta, Gabriele Medeot, Pierre Chanquion:
A deep learning method for enforcing coherence in Automatic Chord Recognition.
443-451
<ee>https://archives.ismir.net/ismir2021/paper/000055.pdf</ee>
<li>Martin A Miguel, Diego Fernandez Slezak:
Modeling beat uncertainty as a 2D distribution of period and phase: a MIR task proposal.
452-459
<ee>https://archives.ismir.net/ismir2021/paper/000056.pdf</ee>
<li>Olof Misgeld, Torbjörn L Gulz, Jūra Miniotaitė, Andre Holzapfel:
A case study of deep enculturation and sensorimotor synchronization to real music.
460-467
<ee>https://archives.ismir.net/ismir2021/paper/000057.pdf</ee>
<li>Gautam Mittal, Jesse Engel, Curtis Hawthorne, Ian Simon:
Symbolic Music Generation with Diffusion Models.
468-475
<ee>https://archives.ismir.net/ismir2021/paper/000058.pdf</ee>
<li>Faraaz Nadeem:
Learning from Musical Feedback with Sonic the Hedgehog.
476-483
<ee>https://archives.ismir.net/ismir2021/paper/000059.pdf</ee>
<li>Javier Nistal, Stefan Lattner, Gaël Richard:
DarkGAN: Exploiting Knowledge Distillation for Comprehensible Audio Synthesis With GANs.
484-492
<ee>https://archives.ismir.net/ismir2021/paper/000060.pdf</ee>
<li>Takehisa Oyama, Ryoto Ishizuka, Kazuyoshi Yoshii:
Phase-Aware Joint Beat and Downbeat Estimation Based on Periodicity of Metrical Structure.
493-499
<ee>https://archives.ismir.net/ismir2021/paper/000061.pdf</ee>
<li>Yuto Ozaki, John M Mcbride, Emmanouil Benetos, Peter Pfordresher, Joren Six, Adam Tierney, Polina Proutskova, Emi Sakai, Haruka Kondo, Haruno Fukatsu, Shinya Fujii, Patrick E. Savage:
Agreement Among Human and Automated Transcriptions of Global Songs.
500-508
<ee>https://archives.ismir.net/ismir2021/paper/000062.pdf</ee>
<li>Emilia Parada-Cabaleiro, Maximilian Schmitt, Anton Batliner, Bjorn W. Schuller, Markus Schedl:
Automatic Recognition of Texture in Renaissance Music.
509-516
<ee>https://archives.ismir.net/ismir2021/paper/000063.pdf</ee>
<li>Ashis Pati, Alexander Lerch:
Is Disentanglement enough? On Latent Representations for Controllable Music Generation.
517-524
<ee>https://archives.ismir.net/ismir2021/paper/000064.pdf</ee>
<li>Nicolás Pironio, Diego Fernandez Slezak, Martin A Miguel:
Pulse clarity metrics developed from a deep learning beat tracking model.
525-530
<ee>https://archives.ismir.net/ismir2021/paper/000065.pdf</ee>
<li>Verena Praher, Katharina Prinz, Arthur Flexer, Gerhard Widmer:
On the Veracity of Local, Model-agnostic Explanations in Audio Classification: Targeted Investigations with Adversarial Examples.
531-538
<ee>https://archives.ismir.net/ismir2021/paper/000066.pdf</ee>
<li>Laure Prétet, Gaël Richard, Geoffroy Peeters:
Is there a "language of music-video clips" ? A qualitative and quantitative study.
539-546
<ee>https://archives.ismir.net/ismir2021/paper/000067.pdf</ee>
<li>Gowriprasad R, Venkatesh V, Hema A Murthy, R Aravind, Sri Rama Murty K:
Tabla Gharana Recognition from Audio music recordings of Tabla Solo performances.
547-554
<ee>https://archives.ismir.net/ismir2021/paper/000068.pdf</ee>
<li>Lindsey Reymore, Emmanuelle Beauvais-Lacasse, Bennett Smith, Stephen Mcadams:
Navigating noise: Modeling perceptual correlates of noise-related semantic timbre categories with audio features.
555-561
<ee>https://archives.ismir.net/ismir2021/paper/000069.pdf</ee>
<li>Kyle Robinson, Dan Brown:
Quantitative User Perceptions of Music Recommendation List Diversity.
562-568
<ee>https://archives.ismir.net/ismir2021/paper/000070.pdf</ee>
<li>Martin A Rohrmeier, Fabian C. Moss:
A Formal Model of Extended Tonal Harmony.
569-578
<ee>https://archives.ismir.net/ismir2021/paper/000071.pdf</ee>
<li>Simon Rouard, Gaëtan Hadjeres:
CRASH: Raw Audio Score-based Generative Modeling for Controllable High-resolution Drum Sound Synthesis.
579-585
<ee>https://archives.ismir.net/ismir2021/paper/000072.pdf</ee>
<li>Luke O Rowe, George Tzanetakis:
Curriculum Learning for Imbalanced Classification in Large Vocabulary Automatic Chord Recognition.
586-593
<ee>https://archives.ismir.net/ismir2021/paper/000073.pdf</ee>
<li>Justin Salamon, Oriol Nieto, Nicholas J. Bryan:
Deep Embeddings and Section Fusion Improve Music Segmentation.
594-601
<ee>https://archives.ismir.net/ismir2021/paper/000074.pdf</ee>
<li>Antonia Saravanou, Federico Tomasi, Rishabh Mehrotra, Mounia Lalmas:
Multi-Task Learning of Graph-based Inductive Representations of Music Content.
602-609
<ee>https://archives.ismir.net/ismir2021/paper/000075.pdf</ee>
<li>Pedro Pereira Sarmento, Adarsh Kumar, Cj Carr, Zack Zukowski, Mathieu Barthet, Yi-Hsuan Yang:
DadaGP: A Dataset of Tokenized GuitarPro Songs for Sequence Models.
610-617
<ee>https://archives.ismir.net/ismir2021/paper/000076.pdf</ee>
<li>Harald Victor Schweiger, Emilia Parada-Cabaleiro, Markus Schedl:
Does Track Sequence in User-generated Playlists Matter?.
618-625
<ee>https://archives.ismir.net/ismir2021/paper/000077.pdf</ee>
<li>Simon J Schwär, Sebastian Rosenzweig, Meinard Müller:
A Differentiable Cost Measure for Intonation Processing in Polyphonic Music.
626-633
<ee>https://archives.ismir.net/ismir2021/paper/000078.pdf</ee>
<li>Pavan M Seshadri, Alexander Lerch:
Improving Music Performance Assessment With Contrastive Learning.
634-641
<ee>https://archives.ismir.net/ismir2021/paper/000079.pdf</ee>
<li>Dougal Shakespeare, Camille Roth:
Tracing Affordance and Item Adoption on Music Streaming Platforms.
642-649
<ee>https://archives.ismir.net/ismir2021/paper/000080.pdf</ee>
<li>Zhengshan Shi:
Computational analysis and modeling of expressive timing in Chopin's Mazurkas.
650-656
<ee>https://archives.ismir.net/ismir2021/paper/000081.pdf</ee>
<li>Nithya Nadig Shikarpur, Asawari Keskar, Preeti Rao:
Computational analysis of melodic mode switching in raga performance.
657-664
<ee>https://archives.ismir.net/ismir2021/paper/000082.pdf</ee>
<li>Qingwei Song, Qiwei Sun, Dongsheng Guo, Haiyong Zheng:
SinTra: Learning an inspiration model from a single multi-track music segment.
665-672
<ee>https://archives.ismir.net/ismir2021/paper/000083.pdf</ee>
<li>Janne Spijkervet, John Ashley Burgoyne:
Contrastive Learning of Musical Representations.
673-681
<ee>https://archives.ismir.net/ismir2021/paper/000084.pdf</ee>
<li>Xiaoheng Sun, Qiqi He, Gao Yongwei, Wei Li:
Musical Tempo Estimation Using a Multi-scale Network.
682-689
<ee>https://archives.ismir.net/ismir2021/paper/000085.pdf</ee>
<li>Pau Torras, Arnau Baró, Lei Kang, Alicia Fornés:
On the Integration of Language Models into Sequence to Sequence Architectures for Handwritten Music Recognition.
690-696
<ee>https://archives.ismir.net/ismir2021/paper/000086.pdf</ee>
<li>Kosetsu Tsukuda, Keisuke Ishida, Masahiro Hamasaki, Masataka Goto:
Kiite Cafe: A Web Service for Getting Together Virtually to Listen to Music.
697-704
<ee>https://archives.ismir.net/ismir2021/paper/000087.pdf</ee>
<li>Kosetsu Tsukuda, Masahiro Hamasaki, Masataka Goto:
Toward an Understanding of Lyrics-viewing Behavior While Listening to Music on a Smartphone.
705-713
<ee>https://archives.ismir.net/ismir2021/paper/000088.pdf</ee>
<li>Andrea Vaglio, Romain Hennequin, Manuel Moussallam, Gael Richard:
The Words Remain the Same: Cover Detection with Lyrics Transcription.
714-721
<ee>https://archives.ismir.net/ismir2021/paper/000089.pdf</ee>
<li>Ziyu Wang, Gus Xia:
MuseBERT: Pre-training Music Representation for Music Understanding and Controllable Generation.
722-729
<ee>https://archives.ismir.net/ismir2021/paper/000090.pdf</ee>
<li>Ju-Chiang Wang, Jordan B. L. Smith, Wei-Tsung Lu, Xuchen Song:
Supervised Metric Learning For Music Structure Features.
730-737
<ee>https://archives.ismir.net/ismir2021/paper/000091.pdf</ee>
<li>Shiqi Wei, Gus Xia:
Learning long-term music representations via hierarchical contextual constraints.
738-745
<ee>https://archives.ismir.net/ismir2021/paper/000092.pdf</ee>
<li>Christof Weiss, Johannes Zeitler, Tim Zunner, Florian Schuberth, Meinard Müller:
Learning Pitch-Class Representations from Score-Audio Pairs of Classical Music.
746-753
<ee>https://archives.ismir.net/ismir2021/paper/000093.pdf</ee>
<li>Christof Weiss, Geoffroy Peeters:
Training Deep Pitch-Class Representations With a Multi-Label CTC Loss.
754-761
<ee>https://archives.ismir.net/ismir2021/paper/000094.pdf</ee>
<li>Daniel Wolff, Remi Mignot, Axel Roebel:
Audio Defect Detection in Music with Deep Networks.
762-768
<ee>https://archives.ismir.net/ismir2021/paper/000095.pdf</ee>
<li>Minz Won, Keunwoo Choi, Xavier Serra:
Semi-supervised Music Tagging Transformer.
769-776
<ee>https://archives.ismir.net/ismir2021/paper/000096.pdf</ee>
<li>Minz Won, Justin Salamon, Nicholas J. Bryan, Gautham Mysore, Xavier Serra:
Emotion Embedding Spaces for Matching Music to Stories.
777-785
<ee>https://archives.ismir.net/ismir2021/paper/000097.pdf</ee>
<li>Abudukelimu Wuerkaixi, Christodoulos Benetatos, Zhiyao Duan, Changshui Zhang:
CollageNet: Fusing arbitrary melody and accompaniment into a coherent song.
786-793
<ee>https://archives.ismir.net/ismir2021/paper/000098.pdf</ee>
<li>Kazuhiko Yamamoto:
Human-in-the-Loop Adaptation for Interactive Musical Beat Tracking.
794-801
<ee>https://archives.ismir.net/ismir2021/paper/000099.pdf</ee>
<li>Daniel Yang, Timothy Tsai:
Composer Classification With Cross-Modal Transfer Learning and Musically-Informed Augmentation.
802-809
<ee>https://archives.ismir.net/ismir2021/paper/000100.pdf</ee>
<li>Daniel Yang, Kevin Ji, Timothy Tsai:
Aligning Unsynchronized Part Recordings to a Full Mix Using Iterative Subtractive Alignment.
810-817
<ee>https://archives.ismir.net/ismir2021/paper/000101.pdf</ee>
<li>Mickael Zehren, Marco Alunno, Paolo Bientinesi:
ADTOF: A large dataset of non-synthetic music for automatic drum transcription.
818-824
<ee>https://archives.ismir.net/ismir2021/paper/000102.pdf</ee>
<li>Huan Zhang, Yiliang Jiang, Tao Jiang, Hu Peng:
Learn by Referencing: Towards Deep Metric Learning for Singing Assessment.
825-832
<ee>https://archives.ismir.net/ismir2021/paper/000103.pdf</ee>
<li>Jingwei Zhao, Gus Xia:
AccoMontage: Accompaniment Arrangement via Phrase Selection and Style Transfer.
833-840
<ee>https://archives.ismir.net/ismir2021/paper/000104.pdf</ee>
</ul>
<footer>
